{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\n# Check if GPU is availableâ‰ \nif torch.cuda.is_available():\n    # Get the number of available GPUs\n    num_gpus = torch.cuda.device_count()\n    print(f\"Number of available GPUs: {num_gpus}\")\n\n    # Get the name of each GPU\n    for i in range(num_gpus):\n        gpu_name = torch.cuda.get_device_name(i)\n        print(f\"GPU {i}: {gpu_name}\")\n\n    # Get the current GPU device\n    current_device = torch.cuda.current_device()\n    print(f\"Current GPU device: {current_device}\")\n\n    # Get GPU properties\n    gpu_properties = torch.cuda.get_device_properties(current_device)\n    print(f\"GPU Properties:\\n{gpu_properties}\")\nelse:\n    print(\"No GPU available. Switching to CPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T03:50:33.009892Z","iopub.execute_input":"2024-01-14T03:50:33.010268Z","iopub.status.idle":"2024-01-14T03:50:36.063340Z","shell.execute_reply.started":"2024-01-14T03:50:33.010235Z","shell.execute_reply":"2024-01-14T03:50:36.062471Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Number of available GPUs: 1\nGPU 0: Tesla P100-PCIE-16GB\nCurrent GPU device: 0\nGPU Properties:\n_CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16276MB, multi_processor_count=56)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchvision.transforms import ToTensor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 1","metadata":{}},{"cell_type":"markdown","source":"## A","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass OneAModule(nn.Module):\n    def __init__(self, in_channels):\n        super(OneAModule, self).__init__()\n\n        # 1x1 conv branch\n        self.branch1 = nn.Conv2d(in_channels, 128, kernel_size=1)\n\n        # 1x1 conv followed by 3x3 conv branch\n        self.branch2 = nn.Sequential(\n            nn.Conv2d(in_channels, 192, kernel_size=3, padding=1)\n        )\n\n        # 1x1 conv followed by 5x5 conv branch\n        self.branch3 = nn.Sequential(\n            nn.Conv2d(in_channels, 96, kernel_size=5, padding=2)\n        )\n\n        # 3x3 max pooling followed by 1x1 conv branch\n        self.branch4 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x):\n        branch1 = self.branch1(x)\n        branch2 = self.branch2(x)\n        branch3 = self.branch3(x)\n        branch4 = self.branch4(x)\n\n        # Concatenate the branches along the channel dimension\n        output = torch.cat([branch1, branch2, branch3, branch4], dim=1)\n\n        return output\n\n# Example usage\nin_channels = 256\nmodel = OneAModule(in_channels)\n\n# Print the model architecture\nprint(model)\n\n# Example input tensor (replace with your data)\ninput_data = torch.randn(1, in_channels, 28, 28)  # Batch size of 1, 28x28x256 input\n\n# Forward pass\noutput = model(input_data)\nprint(\"Output shape:\", output.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T03:50:48.043044Z","iopub.execute_input":"2024-01-14T03:50:48.043513Z","iopub.status.idle":"2024-01-14T03:50:48.179347Z","shell.execute_reply.started":"2024-01-14T03:50:48.043484Z","shell.execute_reply":"2024-01-14T03:50:48.178354Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"OneAModule(\n  (branch1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n  (branch2): Sequential(\n    (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (branch3): Sequential(\n    (0): Conv2d(256, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  )\n  (branch4): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n)\nOutput shape: torch.Size([1, 672, 28, 28])\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}